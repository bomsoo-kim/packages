{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__ = '2019-07-27-beta'\n",
    "__DEBUG_MODE__ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i=1 (level=1, group=1);  {'x': -10, 'y': 0.0, 'z': -10, 'func_value': 227.94}\n",
      "> i=2 (level=1, group=1);  {'x': -10, 'y': 0.0, 'z': -1, 'func_value': 175.73999999999998}\n",
      "> i=3 (level=1, group=1);  {'x': -10, 'y': 0.0, 'z': 5, 'func_value': 230.93999999999997}\n",
      "> i=4 (level=1, group=1);  {'x': -10, 'y': 0.0, 'z': 10, 'func_value': 331.93999999999994}\n",
      "> i=5 (level=1, group=1);  {'x': -10, 'y': 0.01, 'z': -10, 'func_value': 227.8741}\n",
      "> i=6 (level=1, group=1);  {'x': -10, 'y': 0.01, 'z': -1, 'func_value': 175.67409999999998}\n",
      "> i=7 (level=1, group=1);  {'x': -10, 'y': 0.01, 'z': 5, 'func_value': 230.87409999999997}\n",
      "> i=8 (level=1, group=1);  {'x': -10, 'y': 0.01, 'z': 10, 'func_value': 331.8741}\n",
      "> i=9 (level=1, group=1);  {'x': -10, 'y': 4.0, 'z': -10, 'func_value': 217.54000000000002}\n",
      "> i=10 (level=1, group=1);  {'x': -10, 'y': 4.0, 'z': -1, 'func_value': 165.34}\n",
      "> i=11 (level=1, group=1);  {'x': -10, 'y': 4.0, 'z': 5, 'func_value': 220.54}\n",
      "> i=12 (level=1, group=1);  {'x': -10, 'y': 4.0, 'z': 10, 'func_value': 321.53999999999996}\n",
      "> i=13 (level=1, group=1);  {'x': -10, 'y': 10.0, 'z': -10, 'func_value': 261.94}\n",
      "> i=14 (level=1, group=1);  {'x': -10, 'y': 10.0, 'z': -1, 'func_value': 209.74}\n",
      "> i=15 (level=1, group=1);  {'x': -10, 'y': 10.0, 'z': 5, 'func_value': 264.94}\n",
      "> i=16 (level=1, group=1);  {'x': -10, 'y': 10.0, 'z': 10, 'func_value': 365.94}\n",
      "> i=17 (level=1, group=1);  {'x': 3, 'y': 0.0, 'z': -10, 'func_value': 66.74000000000001}\n",
      "> i=18 (level=1, group=1);  {'x': 3, 'y': 0.0, 'z': -1, 'func_value': 14.54}\n",
      "> i=19 (level=1, group=1);  {'x': 3, 'y': 0.0, 'z': 5, 'func_value': 69.74}\n",
      "> i=20 (level=1, group=1);  {'x': 3, 'y': 0.0, 'z': 10, 'func_value': 170.73999999999998}\n",
      "> i=21 (level=1, group=1);  {'x': 3, 'y': 0.01, 'z': -10, 'func_value': 66.67410000000001}\n",
      "> i=22 (level=1, group=1);  {'x': 3, 'y': 0.01, 'z': -1, 'func_value': 14.4741}\n",
      "> i=23 (level=1, group=1);  {'x': 3, 'y': 0.01, 'z': 5, 'func_value': 69.6741}\n",
      "> i=24 (level=1, group=1);  {'x': 3, 'y': 0.01, 'z': 10, 'func_value': 170.67409999999998}\n",
      "> i=25 (level=1, group=1);  {'x': 3, 'y': 4.0, 'z': -10, 'func_value': 56.34}\n",
      "> i=26 (level=1, group=1);  {'x': 3, 'y': 4.0, 'z': -1, 'func_value': 4.140000000000001}\n",
      "> i=27 (level=1, group=1);  {'x': 3, 'y': 4.0, 'z': 5, 'func_value': 59.339999999999996}\n",
      "> i=28 (level=1, group=1);  {'x': 3, 'y': 4.0, 'z': 10, 'func_value': 160.34}\n",
      "> i=29 (level=1, group=1);  {'x': 3, 'y': 10.0, 'z': -10, 'func_value': 100.74000000000001}\n",
      "> i=30 (level=1, group=1);  {'x': 3, 'y': 10.0, 'z': -1, 'func_value': 48.540000000000006}\n",
      "> i=31 (level=1, group=1);  {'x': 3, 'y': 10.0, 'z': 5, 'func_value': 103.74000000000001}\n",
      "> i=32 (level=1, group=1);  {'x': 3, 'y': 10.0, 'z': 10, 'func_value': 204.74}\n",
      "> i=33 (level=1, group=1);  {'x': 10, 'y': 0.0, 'z': -10, 'func_value': 119.94}\n",
      "> i=34 (level=1, group=1);  {'x': 10, 'y': 0.0, 'z': -1, 'func_value': 67.74}\n",
      "> i=35 (level=1, group=1);  {'x': 10, 'y': 0.0, 'z': 5, 'func_value': 122.94}\n",
      "> i=36 (level=1, group=1);  {'x': 10, 'y': 0.0, 'z': 10, 'func_value': 223.94}\n",
      "> i=37 (level=1, group=1);  {'x': 10, 'y': 0.01, 'z': -10, 'func_value': 119.8741}\n",
      "> i=38 (level=1, group=1);  {'x': 10, 'y': 0.01, 'z': -1, 'func_value': 67.6741}\n",
      "> i=39 (level=1, group=1);  {'x': 10, 'y': 0.01, 'z': 5, 'func_value': 122.8741}\n",
      "> i=40 (level=1, group=1);  {'x': 10, 'y': 0.01, 'z': 10, 'func_value': 223.8741}\n",
      "> i=41 (level=1, group=1);  {'x': 10, 'y': 4.0, 'z': -10, 'func_value': 109.54}\n",
      "> i=42 (level=1, group=1);  {'x': 10, 'y': 4.0, 'z': -1, 'func_value': 57.34}\n",
      "> i=43 (level=1, group=1);  {'x': 10, 'y': 4.0, 'z': 5, 'func_value': 112.53999999999999}\n",
      "> i=44 (level=1, group=1);  {'x': 10, 'y': 4.0, 'z': 10, 'func_value': 213.54}\n",
      "> i=45 (level=1, group=1);  {'x': 10, 'y': 10.0, 'z': -10, 'func_value': 153.94}\n",
      "> i=46 (level=1, group=1);  {'x': 10, 'y': 10.0, 'z': -1, 'func_value': 101.74000000000001}\n",
      "> i=47 (level=1, group=1);  {'x': 10, 'y': 10.0, 'z': 5, 'func_value': 156.94}\n",
      "> i=48 (level=1, group=1);  {'x': 10, 'y': 10.0, 'z': 10, 'func_value': 257.94}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -1, 'func_value': 4.140000000000001}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -1, 'func_value': 4.140000000000001}\n",
      "> i=49 (level=2, group=2);  {'x': -4, 'y': 4.0, 'z': -1.0, 'func_value': 48.940000000000005}\n",
      "> i=50 (level=2, group=2);  {'x': 6, 'y': 4.0, 'z': -1.0, 'func_value': 14.94}\n",
      "> i=51 (level=2, group=2);  {'x': 3, 'y': 0.2, 'z': -1.0, 'func_value': 13.259999999999998}\n",
      "> i=52 (level=2, group=2);  {'x': 3, 'y': 6.324555320336759, 'z': -1.0, 'func_value': 12.797934885777396}\n",
      "> i=53 (level=2, group=2);  {'x': 3, 'y': 4.0, 'z': -5.5, 'func_value': 9.99}\n",
      "> i=54 (level=2, group=2);  {'x': 3, 'y': 4.0, 'z': 2.0, 'func_value': 22.74}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -1.0, 'func_value': 4.140000000000001}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -1.0, 'func_value': 4.140000000000001}\n",
      "> i=55 (level=3, group=2);  {'x': 0, 'y': 4.0, 'z': -1.0, 'func_value': 11.340000000000002}\n",
      "> i=56 (level=3, group=2);  {'x': 4, 'y': 4.0, 'z': -1.0, 'func_value': 5.74}\n",
      "> i=57 (level=3, group=2);  {'x': 3, 'y': 0.8944271909999159, 'z': -1.0, 'func_value': 9.436780539400555}\n",
      "> i=58 (level=3, group=2);  {'x': 3, 'y': 5.029733718731742, 'z': -1.0, 'func_value': 6.641978737717542}\n",
      "> i=59 (level=3, group=2);  {'x': 3, 'y': 4.0, 'z': -3.25, 'func_value': 2.0025}\n",
      "> i=60 (level=3, group=2);  {'x': 3, 'y': 4.0, 'z': 0.5, 'func_value': 11.190000000000001}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -3.25, 'func_value': 2.0025}\n",
      "> i=61 (level=3, group=3);  {'x': 0, 'y': 4.0, 'z': -3.25, 'func_value': 9.2025}\n",
      "> i=62 (level=3, group=3);  {'x': 4, 'y': 4.0, 'z': -3.25, 'func_value': 3.6024999999999996}\n",
      "> i=63 (level=3, group=3);  {'x': 3, 'y': 0.8944271909999159, 'z': -3.25, 'func_value': 7.299280539400554}\n",
      "> i=64 (level=3, group=3);  {'x': 3, 'y': 5.029733718731742, 'z': -3.25, 'func_value': 4.504478737717541}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -3.25, 'func_value': 2.0025}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -3.25, 'func_value': 2.0025}\n",
      "> i=65 (level=4, group=2);  {'x': 2, 'y': 4.0, 'z': -3.25, 'func_value': 2.4025000000000003}\n",
      "> i=66 (level=4, group=2);  {'x': 3, 'y': 1.8914832180063517, 'z': -3.25, 'func_value': 3.496419525157742}\n",
      "> i=67 (level=4, group=2);  {'x': 3, 'y': 4.4854135678805545, 'z': -3.25, 'func_value': 2.917705326915306}\n",
      "> i=68 (level=4, group=2);  {'x': 3, 'y': 4.0, 'z': -4.375, 'func_value': 4.730625}\n",
      "> i=69 (level=4, group=2);  {'x': 3, 'y': 4.0, 'z': -2.125, 'func_value': 1.8056250000000003}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -2.125, 'func_value': 1.8056250000000003}\n",
      "> i=70 (level=4, group=3);  {'x': 2, 'y': 4.0, 'z': -2.125, 'func_value': 2.2056250000000004}\n",
      "> i=71 (level=4, group=3);  {'x': 4, 'y': 4.0, 'z': -2.125, 'func_value': 3.4056249999999997}\n",
      "> i=72 (level=4, group=3);  {'x': 3, 'y': 1.8914832180063517, 'z': -2.125, 'func_value': 3.299544525157742}\n",
      "> i=73 (level=4, group=3);  {'x': 3, 'y': 4.4854135678805545, 'z': -2.125, 'func_value': 2.7208303269153062}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -2.125, 'func_value': 1.8056250000000003}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -2.125, 'func_value': 1.8056250000000003}\n",
      "> i=74 (level=5, group=2);  {'x': 3, 'y': 2.7506240877345283, 'z': -2.125, 'func_value': 1.617438892977519}\n",
      "> i=75 (level=5, group=2);  {'x': 3, 'y': 4.235758995920592, 'z': -2.125, 'func_value': 2.191269898446315}\n",
      "> i=76 (level=5, group=2);  {'x': 3, 'y': 4.0, 'z': -2.6875, 'func_value': 1.5876562500000002}\n",
      "> i=77 (level=5, group=2);  {'x': 3, 'y': 4.0, 'z': -1.5625, 'func_value': 2.6564062500000003}\n",
      "  best so far = {'x': 3, 'y': 4.0, 'z': -2.6875, 'func_value': 1.5876562500000002}\n",
      "> i=78 (level=5, group=3);  {'x': 2, 'y': 4.0, 'z': -2.6875, 'func_value': 1.9876562500000006}\n",
      "> i=79 (level=5, group=3);  {'x': 4, 'y': 4.0, 'z': -2.6875, 'func_value': 3.18765625}\n",
      "> i=80 (level=5, group=3);  {'x': 3, 'y': 2.7506240877345283, 'z': -2.6875, 'func_value': 1.399470142977519}\n",
      "> i=81 (level=5, group=3);  {'x': 3, 'y': 4.235758995920592, 'z': -2.6875, 'func_value': 1.9733011484463145}\n",
      "  best so far = {'x': 3, 'y': 2.7506240877345283, 'z': -2.6875, 'func_value': 1.399470142977519}\n",
      "> i=82 (level=5, group=4);  {'x': 2, 'y': 2.7506240877345283, 'z': -2.6875, 'func_value': 1.7994701429775195}\n",
      "> i=83 (level=5, group=4);  {'x': 4, 'y': 2.7506240877345283, 'z': -2.6875, 'func_value': 2.9994701429775183}\n",
      "> i=84 (level=5, group=4);  {'x': 3, 'y': 1.8914832180063517, 'z': -2.6875, 'func_value': 3.0815757751577424}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i=85 (level=5, group=4);  {'x': 3, 'y': 2.7506240877345283, 'z': -3.25, 'func_value': 1.8143138929775189}\n",
      "  best so far = {'x': 3, 'y': 2.7506240877345283, 'z': -2.6875, 'func_value': 1.399470142977519}\n",
      "  best so far = {'x': 3, 'y': 2.7506240877345283, 'z': -2.6875, 'func_value': 1.399470142977519}\n",
      "> i=86 (level=6, group=2);  {'x': 3, 'y': 2.280955786724918, 'z': -2.6875, 'func_value': 2.13610735860943}\n",
      "> i=87 (level=6, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.6875, 'func_value': 1.0979452876756104}\n",
      "> i=88 (level=6, group=2);  {'x': 3, 'y': 2.7506240877345283, 'z': -2.96875, 'func_value': 1.5277904554775188}\n",
      "> i=89 (level=6, group=2);  {'x': 3, 'y': 2.7506240877345283, 'z': -2.40625, 'func_value': 1.429352955477519}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.6875, 'func_value': 1.0979452876756104}\n",
      "> i=90 (level=6, group=3);  {'x': 2, 'y': 3.3170011080700763, 'z': -2.6875, 'func_value': 1.4979452876756105}\n",
      "> i=91 (level=6, group=3);  {'x': 4, 'y': 3.3170011080700763, 'z': -2.6875, 'func_value': 2.69794528767561}\n",
      "> i=92 (level=6, group=3);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.96875, 'func_value': 1.2262656001756103}\n",
      "> i=93 (level=6, group=3);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.40625, 'func_value': 1.1278281001756103}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.6875, 'func_value': 1.0979452876756104}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.6875, 'func_value': 1.0979452876756104}\n",
      "> i=94 (level=7, group=2);  {'x': 3, 'y': 3.020566693006409, 'z': -2.6875, 'func_value': 1.1757392230573744}\n",
      "> i=95 (level=7, group=2);  {'x': 3, 'y': 3.642527204054941, 'z': -2.6875, 'func_value': 1.2149811355176952}\n",
      "> i=96 (level=7, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.828125, 'func_value': 1.1423300533006102}\n",
      "> i=97 (level=7, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.546875, 'func_value': 1.0931113033006103}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.546875, 'func_value': 1.0931113033006103}\n",
      "> i=98 (level=7, group=3);  {'x': 2, 'y': 3.3170011080700763, 'z': -2.546875, 'func_value': 1.4931113033006107}\n",
      "> i=99 (level=7, group=3);  {'x': 4, 'y': 3.3170011080700763, 'z': -2.546875, 'func_value': 2.69311130330061}\n",
      "> i=100 (level=7, group=3);  {'x': 3, 'y': 3.020566693006409, 'z': -2.546875, 'func_value': 1.1709052386823744}\n",
      "> i=101 (level=7, group=3);  {'x': 3, 'y': 3.642527204054941, 'z': -2.546875, 'func_value': 1.210147151142695}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.546875, 'func_value': 1.0931113033006103}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.546875, 'func_value': 1.0931113033006103}\n",
      "> i=102 (level=8, group=2);  {'x': 3, 'y': 3.1653156347672224, 'z': -2.546875, 'func_value': 1.110962143863156}\n",
      "> i=103 (level=8, group=2);  {'x': 3, 'y': 3.475955519281804, 'z': -2.546875, 'func_value': 1.1237826103907294}\n",
      "> i=104 (level=8, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.6171875, 'func_value': 1.0905844478318603}\n",
      "> i=105 (level=8, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.4765625, 'func_value': 1.1055258540818604}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.6171875, 'func_value': 1.0905844478318603}\n",
      "> i=106 (level=8, group=3);  {'x': 2, 'y': 3.3170011080700763, 'z': -2.6171875, 'func_value': 1.4905844478318606}\n",
      "> i=107 (level=8, group=3);  {'x': 4, 'y': 3.3170011080700763, 'z': -2.6171875, 'func_value': 2.69058444783186}\n",
      "> i=108 (level=8, group=3);  {'x': 3, 'y': 3.1653156347672224, 'z': -2.6171875, 'func_value': 1.108435288394406}\n",
      "> i=109 (level=8, group=3);  {'x': 3, 'y': 3.475955519281804, 'z': -2.6171875, 'func_value': 1.1212557549219793}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.6171875, 'func_value': 1.0905844478318603}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.6171875, 'func_value': 1.0905844478318603}\n",
      "> i=110 (level=9, group=2);  {'x': 3, 'y': 3.2402708942177063, 'z': -2.6171875, 'func_value': 1.0938629762338024}\n",
      "> i=111 (level=9, group=2);  {'x': 3, 'y': 3.3955483075727315, 'z': -2.6171875, 'func_value': 1.0994248892362632}\n",
      "> i=112 (level=9, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.65234375, 'func_value': 1.0930289058396727}\n",
      "> i=113 (level=9, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.58203125, 'func_value': 1.0906119136521728}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.6171875, 'func_value': 1.0905844478318603}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.6171875, 'func_value': 1.0905844478318603}\n",
      "> i=114 (level=10, group=2);  {'x': 3, 'y': 3.2784115279457136, 'z': -2.6171875, 'func_value': 1.0907614722818886}\n",
      "> i=115 (level=10, group=2);  {'x': 3, 'y': 3.3560449190563917, 'z': -2.6171875, 'func_value': 1.0934364431082875}\n",
      "> i=116 (level=10, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.634765625, 'func_value': 1.091497686357251}\n",
      "> i=117 (level=10, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.599609375, 'func_value': 1.090289190263501}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.599609375, 'func_value': 1.090289190263501}\n",
      "> i=118 (level=10, group=3);  {'x': 2, 'y': 3.3170011080700763, 'z': -2.599609375, 'func_value': 1.4902891902635012}\n",
      "> i=119 (level=10, group=3);  {'x': 4, 'y': 3.3170011080700763, 'z': -2.599609375, 'func_value': 2.6902891902635004}\n",
      "> i=120 (level=10, group=3);  {'x': 3, 'y': 3.2784115279457136, 'z': -2.599609375, 'func_value': 1.0904662147135293}\n",
      "> i=121 (level=10, group=3);  {'x': 3, 'y': 3.3560449190563917, 'z': -2.599609375, 'func_value': 1.093141185539928}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.599609375, 'func_value': 1.090289190263501}\n",
      "  best so far = {'x': 3, 'y': 3.3170011080700763, 'z': -2.599609375, 'func_value': 1.090289190263501}\n",
      "> i=122 (level=11, group=2);  {'x': 3, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 1.0900056756947778}\n",
      "> i=123 (level=11, group=2);  {'x': 3, 'y': 3.3364659020051444, 'z': -2.599609375, 'func_value': 1.0913299145969393}\n",
      "> i=124 (level=11, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.6083984375, 'func_value': 1.0903595714280516}\n",
      "> i=125 (level=11, group=2);  {'x': 3, 'y': 3.3170011080700763, 'z': -2.5908203125, 'func_value': 1.090373304338208}\n",
      "  best so far = {'x': 3, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 1.0900056756947778}\n",
      "> i=126 (level=11, group=3);  {'x': 2, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 1.4900056756947782}\n",
      "> i=127 (level=11, group=3);  {'x': 4, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 2.690005675694777}\n",
      "> i=128 (level=11, group=3);  {'x': 3, 'y': 3.2976498708785997, 'z': -2.6083984375, 'func_value': 1.0900760568593286}\n",
      "> i=129 (level=11, group=3);  {'x': 3, 'y': 3.2976498708785997, 'z': -2.5908203125, 'func_value': 1.0900897897694848}\n",
      "  best so far = {'x': 3, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 1.0900056756947778}\n",
      "  best so far = {'x': 3, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 1.0900056756947778}\n",
      "> i=130 (level=12, group=2);  {'x': 3, 'y': 3.2880166288839074, 'z': -2.599609375, 'func_value': 1.0901437537711964}\n",
      "> i=131 (level=12, group=2);  {'x': 3, 'y': 3.3073113363775506, 'z': -2.599609375, 'func_value': 1.0900536082275163}\n",
      "> i=132 (level=12, group=2);  {'x': 3, 'y': 3.2976498708785997, 'z': -2.60400390625, 'func_value': 1.0900215543721459}\n",
      "> i=133 (level=12, group=2);  {'x': 3, 'y': 3.2976498708785997, 'z': -2.59521484375, 'func_value': 1.090028420827224}\n",
      "  best so far = {'x': 3, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 1.0900056756947778}\n",
      "  best so far = {'x': 3, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 1.0900056756947778}\n",
      "> i=134 (level=13, group=2);  {'x': 3, 'y': 3.2928297271018594, 'z': -2.599609375, 'func_value': 1.0900515654013243}\n",
      "> i=135 (level=13, group=2);  {'x': 3, 'y': 3.3024770705276305, 'z': -2.599609375, 'func_value': 1.0900062884662893}\n",
      "> i=136 (level=13, group=2);  {'x': 3, 'y': 3.2976498708785997, 'z': -2.601806640625, 'func_value': 1.090008787057235}\n",
      "> i=137 (level=13, group=2);  {'x': 3, 'y': 3.2976498708785997, 'z': -2.597412109375, 'func_value': 1.0900122202847742}\n",
      "  best so far = {'x': 3, 'y': 3.2976498708785997, 'z': -2.599609375, 'func_value': 1.0900056756947778}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross grid search completed...\n",
      "best param =  {'x': 3, 'y': 3.2976498708785997, 'z': -2.599609375}\n",
      "     func_value    x         y         z\n",
      "121    1.090006  3.0  3.297650 -2.599609\n",
      "134    1.090006  3.0  3.302477 -2.599609\n",
      "131    1.090022  3.0  3.297650 -2.604004\n",
      "116    1.090289  3.0  3.317001 -2.599609\n",
      "103    1.090584  3.0  3.317001 -2.617188\n",
      "112    1.090612  3.0  3.317001 -2.582031\n",
      "96     1.093111  3.0  3.317001 -2.546875\n",
      "86     1.097945  3.0  3.317001 -2.687500\n",
      "79     1.399470  3.0  2.750624 -2.687500\n",
      "68     1.805625  3.0  4.000000 -2.125000\n",
      "58     2.002500  3.0  4.000000 -3.250000\n",
      "25     4.140000  3.0  4.000000 -1.000000\n",
      "52     9.990000  3.0  4.000000 -5.500000\n"
     ]
    }
   ],
   "source": [
    "# Copyright Â© 2018-2019 Bomsoo Brad Kim, All Rights Reserved.\n",
    "# Last Update : 04/14/2019\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def xgrid_search(xgrid_search_target_function, params, \n",
    "                 MIN_MAX = 'min', SCORE_TOLERANCE = 1e-5,  MAX_GRID_LEVEL = 20, MAX_INNER_ROUND = 50, \n",
    "                 initialize_cross_grid = False):\n",
    "    def generate_cgrid(ikeys): # make cross grids\n",
    "        iparams2 = {k: [0,-1,1] for k in ikeys}\n",
    "        cgrid = pd.DataFrame(columns = ikeys) # initialize cgrid with empty elements\n",
    "        for k,i in iparams2.items():\n",
    "            cgrid = pd.concat([cgrid, pd.DataFrame({k:i})], sort = False) # make cross grids\n",
    "        cgrid.fillna(0, inplace = True)\n",
    "        cgrid.drop_duplicates(keep = 'first', inplace = True)\n",
    "        cgrid.reset_index(drop = True, inplace = True)\n",
    "        return cgrid\n",
    "\n",
    "    def trim_grid(grid, ikeys, min_grid, max_grid): # remove duplicate and out-of-range grid points\n",
    "        i0 = grid[ikeys].duplicated(keep = 'first') # find out which are duplicate elements except the first elements\n",
    "        i1 = (grid[ikeys] < min_grid[ikeys]).any(axis = 1) # find out rows with less than min indexes\n",
    "        i2 = (grid[ikeys] > max_grid[ikeys]).any(axis = 1) # find out rows with greater than max indexes\n",
    "        # grid = pd.concat([grid, i0, i1, i2], sort = False, ignore_index = True, axis = 1)\n",
    "        grid = grid.loc[~(i0 | i1 | i2)] # remove duplicate and out-of-range grid points\n",
    "        grid.reset_index(drop = True, inplace = True)\n",
    "        return grid\n",
    "\n",
    "    def fill_keys(params2, grid):\n",
    "        for (k,i) in params2.items(): grid[k] = grid['i_'+k].map({i:value for i, value in enumerate(params2[k])}) # update index\n",
    "        return grid\n",
    "\n",
    "    def update_divide_intervals(partype, params2, grid):\n",
    "        def divide_intervals(a, paramter_type = 'uni'):\n",
    "            a = np.array(a)\n",
    "            if paramter_type == 'uni': aa = np.sort(np.unique(np.append(a, (a[1:] + a[:-1])/2)))\n",
    "            elif paramter_type == 'log': aa = np.sort(np.unique(np.append(a, np.sqrt(a[1:]*a[:-1]))))\n",
    "            elif paramter_type == 'int': aa = np.sort(np.unique(np.around(np.append(a, (a[1:] + a[:-1])/2)).astype(int)))\n",
    "            return aa\n",
    "        for (k,i) in params2.items():\n",
    "            params2[k] = divide_intervals(i, partype[k]) # divide intervals\n",
    "            grid['i_'+k] = grid[k].map({value:i for i, value in enumerate(params2[k])}) # update index\n",
    "        return params2, grid\n",
    "    \n",
    "    \n",
    "    # initial preparation\n",
    "    partype = {k:i[0] for (k,i) in params.items()} # pick up data type\n",
    "    params2 = {k:np.sort(np.unique(i[1])) for (k,i) in params.items()} # pick up range\n",
    "    iparams = {'i_'+k:range(len(i)) for (k,i) in params2.items()} # index for parameters\n",
    "    pkeys = list(params2.keys())\n",
    "    ikeys = list(iparams.keys()) # parameter key names\n",
    "    cgrid = generate_cgrid(ikeys) # cross grid\n",
    "    \n",
    "    # initialize grid\n",
    "    grid = pd.DataFrame(index = pd.MultiIndex.from_product(iparams.values(), names = iparams.keys())).reset_index() # https://stackoverflow.com/questions/13269890/cartesian-product-in-pandas\n",
    "    grid['func_value'] = np.nan\n",
    "    grid = fill_keys(params2, grid)\n",
    "    \n",
    "    # cross grid setting in the first place\n",
    "    if initialize_cross_grid:\n",
    "        params2, grid = update_divide_intervals(partype, params2, grid)\n",
    "        grid = grid[ikeys].mean(axis = 0).astype(int) + cgrid\n",
    "        grid[ikeys].astype(int)\n",
    "        grid['func_value'] = np.nan\n",
    "        grid = fill_keys(params2, grid)\n",
    "\n",
    "    # search for the best\n",
    "    best_fval = pd.DataFrame()\n",
    "    len_prev_grid = 0\n",
    "    for nn in range(MAX_GRID_LEVEL):\n",
    "        for kk in range(MAX_INNER_ROUND):\n",
    "            # evaluate function\n",
    "            for i in range(len(grid)):\n",
    "                if np.isnan(grid.loc[i,'func_value']): # if func_value = nan, then evaluate\n",
    "                    grid.loc[i,'func_value'] = xgrid_search_target_function(**grid.astype(object).loc[i, pkeys].to_dict())\n",
    "                    print('> i=%s (level=%s, group=%s); '%(i+1,nn+1,kk+1), grid.astype(object).loc[i, pkeys+['func_value']].to_dict())\n",
    "            # find best score\n",
    "            if MIN_MAX == 'max': idx = grid['func_value'].idxmax()\n",
    "            elif MIN_MAX == 'min': idx = grid['func_value'].idxmin()\n",
    "            best_grid = grid.loc[idx, ikeys].astype('int') # ensure that the index is integer\n",
    "            print('  best so far =', grid.astype(object).loc[idx, pkeys+['func_value']].to_dict())\n",
    "            # explore new grid points\n",
    "            min_grid = grid.min(axis = 0) # order matters!\n",
    "            max_grid = grid.max(axis = 0) # order matters!\n",
    "            grid = pd.concat([grid, best_grid + cgrid], sort = False, ignore_index = True) # attach new rows\n",
    "            grid = trim_grid(grid, ikeys, min_grid, max_grid) # remove duplicate and out-of-range rows\n",
    "            grid = fill_keys(params2, grid)\n",
    "            # stop if there is no NAN value\n",
    "            if ~grid['func_value'].isna().any(): break\n",
    "\n",
    "        # stop condition\n",
    "        if len_prev_grid == len(grid):\n",
    "            break\n",
    "        else:\n",
    "            if MIN_MAX == 'max': \n",
    "                idx = grid.loc[len_prev_grid:, 'func_value'].idxmax() # find the best at the latest level\n",
    "                best_fval = best_fval.append(grid.loc[idx, pkeys+['func_value']]) # save the best row\n",
    "                best_fval.sort_values(by = 'func_value', ascending  = False, inplace = True)\n",
    "            elif MIN_MAX == 'min': \n",
    "                idx = grid.loc[len_prev_grid:, 'func_value'].idxmin() # find the best at the latest level\n",
    "                best_fval = best_fval.append(grid.loc[idx, pkeys+['func_value']]) # save the best row\n",
    "                best_fval.sort_values(by = 'func_value', ascending  = True, inplace = True)\n",
    "            best_fval.drop_duplicates(keep = 'first', inplace = True)\n",
    "            if len(best_fval) >= 2:\n",
    "                best_fval_values = best_fval['func_value'].values\n",
    "                if abs((best_fval_values[0] - best_fval_values[1])/best_fval_values[0]) < SCORE_TOLERANCE:\n",
    "                    print('cross grid search completed...'); break;\n",
    "        len_prev_grid = len(grid)\n",
    "\n",
    "        # devide intervals\n",
    "        if nn < MAX_GRID_LEVEL - 1: params2, grid = update_divide_intervals(partype, params2, grid)\n",
    "                \n",
    "    if MIN_MAX == 'max': idx = grid['func_value'].idxmax()\n",
    "    elif MIN_MAX == 'min': idx = grid['func_value'].idxmin()\n",
    "    best_param = grid.astype(object).loc[idx, pkeys].to_dict()\n",
    "    \n",
    "    grid.drop(columns = ikeys, inplace = True)\n",
    "    return best_param, best_fval, grid\n",
    "\n",
    "def left_join_crossgridparams_params(xgrid_params, params):\n",
    "    for (k,i) in xgrid_params.items(): \n",
    "        xgrid_params[k][1] = np.sort(np.unique(np.append(xgrid_params[k][1], params[k])))\n",
    "    return xgrid_params\n",
    "\n",
    "#### Getting Started! ##############################################\n",
    "if __DEBUG_MODE__:\n",
    "    def xgrid_search_target_function(**param):\n",
    "        #--- STRAT user definition ---\n",
    "        def any_user_function(x,y,z):\n",
    "            return ((x-2.7)**2) + ((y-3.3)**2) + ((z+2.6)**2) + 1.0\n",
    "        output = any_user_function(**param)\n",
    "        #--- END user definition ---\n",
    "        return output\n",
    "\n",
    "    params = { # define the data type and input varaible range\n",
    "        'x': ['int', [-10, 10]], # uni / log / int\n",
    "        'y': ['log', [0, 0.01, 10]], # uni / log / int\n",
    "        'z': ['uni', [-10, -1, 10]]  # uni / log / int\n",
    "    }\n",
    "\n",
    "    param = {'x': 3, 'y': 4, 'z': 5, 'a': 6, 'b': 7} # sample code for how to use left_join_crossgridparams_params\n",
    "    params = left_join_crossgridparams_params(params, param) # sample code for how to use left_join_crossgridparams_params\n",
    "\n",
    "    best_param, best_fval, grid = xgrid_search(xgrid_search_target_function, params, MIN_MAX = 'min', SCORE_TOLERANCE = 1e-5) # decide on min/max problem and then run!\n",
    "    print('best param = ',best_param)\n",
    "    print(best_fval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "\n",
    "def xgrid_search_boosting(train, test, features, target, params_schedule, model, eval_metric, MIN_MAX, \n",
    "                          CV_MODE = 'cross validation 1', N_FOLD = 5, N_BOOST_ROUND = 10000, EARLY_STOPPING = 50, RAND_SEED = 123): \n",
    "    #--- user_defined_eval_function --------------------------------------------------------------\n",
    "    def user_defined_eval_function(train, test, features, target, model, eval_metric, MIN_MAX, predict_test_output = False):\n",
    "        if CV_MODE == 'validation': # validatoin approach: XGBoost\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(train[features], train[target], test_size=1/N_FOLD, random_state=RAND_SEED)\n",
    "            model.set_params(n_estimators = N_BOOST_ROUND) # initialize n_estimators\n",
    "            model.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_valid, y_valid)], eval_metric = eval_metric, \n",
    "                        early_stopping_rounds = EARLY_STOPPING, verbose = False) #Fit the algorithm on the data\n",
    "            if MIN_MAX == 'max': idx = np.array(list(model.evals_result()['validation_1'].values())).argmax()\n",
    "            elif MIN_MAX == 'min': idx = np.array(list(model.evals_result()['validation_1'].values())).argmin()\n",
    "            model.set_params(n_estimators = idx + 1) # update n_estimators\n",
    "            train_score = np.array(list(model.evals_result()['validation_0'].values())).squeeze()[idx]\n",
    "            valid_score = np.array(list(model.evals_result()['validation_1'].values())).squeeze()[idx]\n",
    "            test_pred = model.predict(test[features])     # computationally not expensive\n",
    "        elif (CV_MODE == 'cross validation 1') and ('XGB' in str(model)): # cross validation 1: XGBoost\n",
    "            dtrain = xgb.DMatrix(train[features], label=train[target], missing=np.nan) # missing value handling: https://www.youtube.com/watch?v=cVqDguNWh4M\n",
    "            cvoutp = xgb.cv(model.get_xgb_params(), dtrain, num_boost_round=N_BOOST_ROUND, verbose_eval=False,\n",
    "                              nfold=N_FOLD, metrics=eval_metric, early_stopping_rounds=EARLY_STOPPING, seed=RAND_SEED) \n",
    "            model.set_params(n_estimators = cvoutp.shape[0]) # update n_estimator \n",
    "            train_score = cvoutp.tail(1)[cvoutp.columns[cvoutp.columns.str.contains('train-.+-mean', regex=True)]].squeeze()\n",
    "            valid_score = cvoutp.tail(1)[cvoutp.columns[cvoutp.columns.str.contains('test-.+-mean', regex=True)]].squeeze()\n",
    "\n",
    "            if predict_test_output == True:\n",
    "                model.fit(train[features], train[target].values.ravel(), eval_metric = eval_metric) #Fit the algorithm on the data\n",
    "                test_pred = model.predict(test[features])    \n",
    "            else: \n",
    "                test_pred = []\n",
    "        elif (CV_MODE == 'cross validation 1') and ('LGB' in str(model)): # cross validation 1: LightGBM\n",
    "            dtrain = lgb.Dataset(train[features], label=train[target])\n",
    "\n",
    "            cvoutp = lgb.cv({k:v for k,v in model.get_params().items() if k not in ['n_estimators', 'silent']}, # exclude n_estimators because of the argument, 'num_boost_round'\n",
    "                            dtrain, num_boost_round=N_BOOST_ROUND, verbose_eval=False, \n",
    "                            nfold=N_FOLD, metrics=eval_metric, early_stopping_rounds=EARLY_STOPPING, seed=RAND_SEED)\n",
    "            model.set_params(n_estimators = len(cvoutp[eval_metric+'-mean'])) # update n_estimator with the best num_boost_round\n",
    "            valid_score = cvoutp[eval_metric+'-mean'][-1] # best CV score\n",
    "\n",
    "            if predict_test_output == True:\n",
    "                model.fit(train[features], train[target].values.ravel(), eval_metric = eval_metric) #Fit the algorithm on the data\n",
    "                test_pred = model.predict(test[features])    \n",
    "            else: \n",
    "                test_pred = []\n",
    "        elif CV_MODE == 'cross validation 2': # cross validation 2: XGBoost, LightGBM\n",
    "#             folds = StratifiedKFold(n_splits=N_FOLD, shuffle=False, random_state=RAND_SEED) # cv n-fold\n",
    "            folds = KFold(n_splits=N_FOLD, shuffle=False, random_state=RAND_SEED) # cv n-fold\n",
    "            oof = np.zeros(len(train))\n",
    "            test_pred = np.zeros(len(test))\n",
    "            for n, (trn_idx, val_idx) in enumerate(folds.split(train[features].values, train[target].values)):\n",
    "                X_train, y_train = train.iloc[trn_idx][features], train.iloc[trn_idx][target].values.ravel()\n",
    "                X_valid, y_valid = train.iloc[val_idx][features], train.iloc[val_idx][target].values.ravel()\n",
    "\n",
    "                model.set_params(n_estimators = N_BOOST_ROUND) # initialize n_estimators\n",
    "                model.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_valid, y_valid)], eval_metric = eval_metric, \n",
    "                            early_stopping_rounds = EARLY_STOPPING, verbose = False) #Fit the algorithm on the data\n",
    "\n",
    "                if eval_metric == 'auc': \n",
    "                    oof[val_idx] = model.predict_proba(X_valid)[:,1]\n",
    "                    test_pred += model.predict_proba(test[features])[:,1] / folds.n_splits\n",
    "                if eval_metric == 'rmse': \n",
    "                    oof[val_idx] = model.predict(X_valid)\n",
    "                    test_pred += model.predict(test[features]) / folds.n_splits\n",
    "\n",
    "            if eval_metric == 'auc': \n",
    "                valid_score = metrics.roc_auc_score(train[target], oof)\n",
    "            if eval_metric == 'rmse': \n",
    "                valid_score = np.sqrt(metrics.mean_squared_error(train[target], oof))\n",
    "        return test_pred, valid_score    \n",
    "    \n",
    "    #--- evaluation function with xgboost, ligthgbm ------------------------------\n",
    "    def xgrid_search_target_function(**param): # define user function with all the input variables\n",
    "        #--- START: user defined function -----------------------------\n",
    "        model.set_params(**param) # update some parameters\n",
    "        test_pred, valid_score = user_defined_eval_function(train, test, features, target, model, eval_metric, MIN_MAX)\n",
    "        #--- END ------------------------------------------------------\n",
    "        return valid_score\n",
    "\n",
    "    #-----------------------------------------------------------------------\n",
    "    tic = time.time()\n",
    "    for params in params_schedule:\n",
    "    #     params = left_join_crossgridparams_params(params, model.get_xgb_params()) # ensure that the latest xgmodel values are included\n",
    "        best_param, best_fval, grid = xgrid_search(xgrid_search_target_function, params, MIN_MAX = MIN_MAX, SCORE_TOLERANCE = 1e-5) # decide on min/max problem and then run!\n",
    "        model.set_params(**best_param) # update some parameters with the best so far\n",
    "        print('Best Param = ',best_param)\n",
    "        print(best_fval)    \n",
    "        print(model)\n",
    "    \n",
    "    test_pred, valid_score = user_defined_eval_function(train, test, features, target, model, eval_metric, MIN_MAX, predict_test_output = True)\n",
    "    toc = time.time()\n",
    "    print('Time Elapsed = %s sec'%(toc - tic))\n",
    "    print('Final Validatoin Score = ',valid_score)\n",
    "    print(model) # final model confirmation\n",
    "    \n",
    "    return model, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "> i=1 (level=1, group=1);  {'learning_rate': 0.1, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.9980422977907255}\n",
      "Best Param =  {'learning_rate': 0.1}\n",
      "   func_value  learning_rate\n",
      "0    0.998042            0.1\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=73, n_jobs=4, num_leaves=31, objective=None,\n",
      "               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "> i=1 (level=1, group=1);  {'num_leaves': 8, 'min_child_samples': 0, 'func_value': 0.9965791790320091}\n",
      "> i=2 (level=1, group=1);  {'num_leaves': 8, 'min_child_samples': 10, 'func_value': 0.9959941130381382}\n",
      "> i=3 (level=1, group=1);  {'num_leaves': 8, 'min_child_samples': 20, 'func_value': 0.9971698718239598}\n",
      "> i=4 (level=1, group=1);  {'num_leaves': 8, 'min_child_samples': 50, 'func_value': 0.9967712162051784}\n",
      "> i=5 (level=1, group=1);  {'num_leaves': 8, 'min_child_samples': 100, 'func_value': 0.9916567592668221}\n",
      "> i=6 (level=1, group=1);  {'num_leaves': 8, 'min_child_samples': 200, 'func_value': 0.9662770260254536}\n",
      "> i=7 (level=1, group=1);  {'num_leaves': 31, 'min_child_samples': 0, 'func_value': 0.9716944073862314}\n",
      "> i=8 (level=1, group=1);  {'num_leaves': 31, 'min_child_samples': 10, 'func_value': 0.9931491010736293}\n",
      "> i=9 (level=1, group=1);  {'num_leaves': 31, 'min_child_samples': 20, 'func_value': 0.9980422977907255}\n",
      "> i=10 (level=1, group=1);  {'num_leaves': 31, 'min_child_samples': 50, 'func_value': 0.9971540199842087}\n",
      "> i=11 (level=1, group=1);  {'num_leaves': 31, 'min_child_samples': 100, 'func_value': 0.9916567592668221}\n",
      "> i=12 (level=1, group=1);  {'num_leaves': 31, 'min_child_samples': 200, 'func_value': 0.9662770260254536}\n",
      "> i=13 (level=1, group=1);  {'num_leaves': 128, 'min_child_samples': 0, 'func_value': 0.9733698923950497}\n",
      "> i=14 (level=1, group=1);  {'num_leaves': 128, 'min_child_samples': 10, 'func_value': 0.9961409240654524}\n",
      "> i=15 (level=1, group=1);  {'num_leaves': 128, 'min_child_samples': 20, 'func_value': 0.9980422977907255}\n",
      "> i=16 (level=1, group=1);  {'num_leaves': 128, 'min_child_samples': 50, 'func_value': 0.9971540199842087}\n",
      "> i=17 (level=1, group=1);  {'num_leaves': 128, 'min_child_samples': 100, 'func_value': 0.9916567592668221}\n",
      "> i=18 (level=1, group=1);  {'num_leaves': 128, 'min_child_samples': 200, 'func_value': 0.9662770260254536}\n",
      "> i=19 (level=1, group=1);  {'num_leaves': 1000, 'min_child_samples': 0, 'func_value': 0.9733698923950497}\n",
      "> i=20 (level=1, group=1);  {'num_leaves': 1000, 'min_child_samples': 10, 'func_value': 0.9961409240654524}\n",
      "> i=21 (level=1, group=1);  {'num_leaves': 1000, 'min_child_samples': 20, 'func_value': 0.9980422977907255}\n",
      "> i=22 (level=1, group=1);  {'num_leaves': 1000, 'min_child_samples': 50, 'func_value': 0.9971540199842087}\n",
      "> i=23 (level=1, group=1);  {'num_leaves': 1000, 'min_child_samples': 100, 'func_value': 0.9916567592668221}\n",
      "> i=24 (level=1, group=1);  {'num_leaves': 1000, 'min_child_samples': 200, 'func_value': 0.9662770260254536}\n",
      "  best so far = {'num_leaves': 31, 'min_child_samples': 20, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'num_leaves': 31, 'min_child_samples': 20, 'func_value': 0.9980422977907255}\n",
      "> i=25 (level=2, group=2);  {'num_leaves': 20, 'min_child_samples': 20, 'func_value': 0.9980099285759663}\n",
      "> i=26 (level=2, group=2);  {'num_leaves': 80, 'min_child_samples': 20, 'func_value': 0.9980422977907255}\n",
      "> i=27 (level=2, group=2);  {'num_leaves': 31, 'min_child_samples': 15, 'func_value': 0.9978701359204504}\n",
      "> i=28 (level=2, group=2);  {'num_leaves': 31, 'min_child_samples': 35, 'func_value': 0.9979362054204822}\n",
      "  best so far = {'num_leaves': 31, 'min_child_samples': 20, 'func_value': 0.9980422977907255}\n",
      "cross grid search completed...\n",
      "Best Param =  {'num_leaves': 31, 'min_child_samples': 20}\n",
      "    func_value  min_child_samples  num_leaves\n",
      "8     0.998042               20.0        31.0\n",
      "25    0.998042               20.0        80.0\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=178, n_jobs=4, num_leaves=31, objective=None,\n",
      "               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "> i=1 (level=1, group=1);  {'min_split_gain': 0, 'func_value': 0.9980422977907255}\n",
      "> i=2 (level=1, group=1);  {'min_split_gain': 1, 'func_value': 0.9888909611236656}\n",
      "> i=3 (level=1, group=1);  {'min_split_gain': 3, 'func_value': 0.980443382613194}\n",
      "> i=4 (level=1, group=1);  {'min_split_gain': 10, 'func_value': 0.9418389797949548}\n",
      "> i=5 (level=1, group=1);  {'min_split_gain': 30, 'func_value': 0.9312336603531571}\n",
      "> i=6 (level=1, group=1);  {'min_split_gain': 100, 'func_value': 0.5}\n",
      "> i=7 (level=1, group=1);  {'min_split_gain': 300, 'func_value': 0.5}\n",
      "> i=8 (level=1, group=1);  {'min_split_gain': 1000, 'func_value': 0.5}\n",
      "  best so far = {'min_split_gain': 0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0, 'func_value': 0.9980422977907255}\n",
      "> i=9 (level=2, group=2);  {'min_split_gain': 0.5, 'func_value': 0.9913602028067435}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=10 (level=3, group=2);  {'min_split_gain': 0.25, 'func_value': 0.9944133911743975}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=11 (level=4, group=2);  {'min_split_gain': 0.125, 'func_value': 0.9955639957526751}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=12 (level=5, group=2);  {'min_split_gain': 0.0625, 'func_value': 0.9960416080541867}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=13 (level=6, group=2);  {'min_split_gain': 0.03125, 'func_value': 0.9960915231984414}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=14 (level=7, group=2);  {'min_split_gain': 0.015625, 'func_value': 0.9970879807357795}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=15 (level=8, group=2);  {'min_split_gain': 0.0078125, 'func_value': 0.9974873018898176}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=16 (level=9, group=2);  {'min_split_gain': 0.00390625, 'func_value': 0.9974552654426869}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=17 (level=10, group=2);  {'min_split_gain': 0.001953125, 'func_value': 0.9978374339380627}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=18 (level=11, group=2);  {'min_split_gain': 0.0009765625, 'func_value': 0.9978296895278028}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=19 (level=12, group=2);  {'min_split_gain': 0.00048828125, 'func_value': 0.9976953724123534}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0, 'func_value': 0.9980422977907255}\n",
      "> i=20 (level=13, group=2);  {'min_split_gain': 0.000244140625, 'func_value': 0.998075635056767}\n",
      "  best so far = {'min_split_gain': 0.000244140625, 'func_value': 0.998075635056767}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  best so far = {'min_split_gain': 0.000244140625, 'func_value': 0.998075635056767}\n",
      "> i=21 (level=14, group=2);  {'min_split_gain': 0.0001220703125, 'func_value': 0.9981432776401331}\n",
      "> i=22 (level=14, group=2);  {'min_split_gain': 0.0003662109375, 'func_value': 0.9979746552073596}\n",
      "  best so far = {'min_split_gain': 0.0001220703125, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'min_split_gain': 0.0001220703125, 'func_value': 0.9981432776401331}\n",
      "> i=23 (level=15, group=2);  {'min_split_gain': 6.103515625e-05, 'func_value': 0.9980099285759663}\n",
      "> i=24 (level=15, group=2);  {'min_split_gain': 0.00018310546875, 'func_value': 0.9979070126239937}\n",
      "  best so far = {'min_split_gain': 0.0001220703125, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'min_split_gain': 0.0001220703125, 'func_value': 0.9981432776401331}\n",
      "> i=25 (level=16, group=2);  {'min_split_gain': 9.1552734375e-05, 'func_value': 0.9979050765214288}\n",
      "> i=26 (level=16, group=2);  {'min_split_gain': 0.000152587890625, 'func_value': 0.9980422977907255}\n",
      "  best so far = {'min_split_gain': 0.0001220703125, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'min_split_gain': 0.0001220703125, 'func_value': 0.9981432776401331}\n",
      "> i=27 (level=17, group=2);  {'min_split_gain': 0.0001068115234375, 'func_value': 0.9981429448725047}\n",
      "> i=28 (level=17, group=2);  {'min_split_gain': 0.0001373291015625, 'func_value': 0.998077571159332}\n",
      "  best so far = {'min_split_gain': 0.0001220703125, 'func_value': 0.9981432776401331}\n",
      "cross grid search completed...\n",
      "Best Param =  {'min_split_gain': 0.0001220703125}\n",
      "    func_value  min_split_gain\n",
      "20    0.998143        0.000122\n",
      "26    0.998143        0.000107\n",
      "19    0.998076        0.000244\n",
      "0     0.998042        0.000000\n",
      "25    0.998042        0.000153\n",
      "22    0.998010        0.000061\n",
      "16    0.997837        0.001953\n",
      "17    0.997830        0.000977\n",
      "18    0.997695        0.000488\n",
      "14    0.997487        0.007812\n",
      "15    0.997455        0.003906\n",
      "13    0.997088        0.015625\n",
      "12    0.996092        0.031250\n",
      "11    0.996042        0.062500\n",
      "10    0.995564        0.125000\n",
      "9     0.994413        0.250000\n",
      "8     0.991360        0.500000\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0001220703125, n_estimators=91, n_jobs=4,\n",
      "               num_leaves=31, objective=None, random_state=123, reg_alpha=0.0,\n",
      "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n",
      "> i=1 (level=1, group=1);  {'subsample': 0.2, 'colsample_bytree': 0.2, 'func_value': 0.9825653056470667}\n",
      "> i=2 (level=1, group=1);  {'subsample': 0.2, 'colsample_bytree': 0.4, 'func_value': 0.9825653056470667}\n",
      "> i=3 (level=1, group=1);  {'subsample': 0.2, 'colsample_bytree': 0.6, 'func_value': 0.9825653056470667}\n",
      "> i=4 (level=1, group=1);  {'subsample': 0.2, 'colsample_bytree': 0.8, 'func_value': 0.9825653056470667}\n",
      "> i=5 (level=1, group=1);  {'subsample': 0.2, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "> i=6 (level=1, group=1);  {'subsample': 0.4, 'colsample_bytree': 0.2, 'func_value': 0.9825653056470667}\n",
      "> i=7 (level=1, group=1);  {'subsample': 0.4, 'colsample_bytree': 0.4, 'func_value': 0.9825653056470667}\n",
      "> i=8 (level=1, group=1);  {'subsample': 0.4, 'colsample_bytree': 0.6, 'func_value': 0.9825653056470667}\n",
      "> i=9 (level=1, group=1);  {'subsample': 0.4, 'colsample_bytree': 0.8, 'func_value': 0.9825653056470667}\n",
      "> i=10 (level=1, group=1);  {'subsample': 0.4, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "> i=11 (level=1, group=1);  {'subsample': 0.6, 'colsample_bytree': 0.2, 'func_value': 0.9825653056470667}\n",
      "> i=12 (level=1, group=1);  {'subsample': 0.6, 'colsample_bytree': 0.4, 'func_value': 0.9825653056470667}\n",
      "> i=13 (level=1, group=1);  {'subsample': 0.6, 'colsample_bytree': 0.6, 'func_value': 0.9825653056470667}\n",
      "> i=14 (level=1, group=1);  {'subsample': 0.6, 'colsample_bytree': 0.8, 'func_value': 0.9825653056470667}\n",
      "> i=15 (level=1, group=1);  {'subsample': 0.6, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "> i=16 (level=1, group=1);  {'subsample': 0.8, 'colsample_bytree': 0.2, 'func_value': 0.9825653056470667}\n",
      "> i=17 (level=1, group=1);  {'subsample': 0.8, 'colsample_bytree': 0.4, 'func_value': 0.9825653056470667}\n",
      "> i=18 (level=1, group=1);  {'subsample': 0.8, 'colsample_bytree': 0.6, 'func_value': 0.9825653056470667}\n",
      "> i=19 (level=1, group=1);  {'subsample': 0.8, 'colsample_bytree': 0.8, 'func_value': 0.9825653056470667}\n",
      "> i=20 (level=1, group=1);  {'subsample': 0.8, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "> i=21 (level=1, group=1);  {'subsample': 1.0, 'colsample_bytree': 0.2, 'func_value': 0.9825653056470667}\n",
      "> i=22 (level=1, group=1);  {'subsample': 1.0, 'colsample_bytree': 0.4, 'func_value': 0.9825653056470667}\n",
      "> i=23 (level=1, group=1);  {'subsample': 1.0, 'colsample_bytree': 0.6, 'func_value': 0.9825653056470667}\n",
      "> i=24 (level=1, group=1);  {'subsample': 1.0, 'colsample_bytree': 0.8, 'func_value': 0.9825653056470667}\n",
      "> i=25 (level=1, group=1);  {'subsample': 1.0, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'subsample': 0.2, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'subsample': 0.2, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "> i=26 (level=2, group=2);  {'subsample': 0.30000000000000004, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "> i=27 (level=2, group=2);  {'subsample': 0.2, 'colsample_bytree': 0.9, 'func_value': 0.9825653056470667}\n",
      "  best so far = {'subsample': 0.2, 'colsample_bytree': 1.0, 'func_value': 0.9981432776401331}\n",
      "cross grid search completed...\n",
      "Best Param =  {'subsample': 0.2, 'colsample_bytree': 1.0}\n",
      "    colsample_bytree  func_value  subsample\n",
      "4                1.0    0.998143        0.2\n",
      "25               1.0    0.998143        0.3\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0001220703125, n_estimators=49, n_jobs=4,\n",
      "               num_leaves=31, objective=None, random_state=123, reg_alpha=0.0,\n",
      "               reg_lambda=0.0, silent=True, subsample=0.2,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n",
      "> i=1 (level=1, group=1);  {'reg_alpha': 0, 'reg_lambda': 0, 'func_value': 0.9981432776401331}\n",
      "> i=2 (level=1, group=1);  {'reg_alpha': 0, 'reg_lambda': 1, 'func_value': 0.9977996194348394}\n",
      "> i=3 (level=1, group=1);  {'reg_alpha': 0, 'reg_lambda': 10, 'func_value': 0.9965905536345787}\n",
      "> i=4 (level=1, group=1);  {'reg_alpha': 0, 'reg_lambda': 100, 'func_value': 0.9953103663166557}\n",
      "> i=5 (level=1, group=1);  {'reg_alpha': 0, 'reg_lambda': 500, 'func_value': 0.9941094079458859}\n",
      "> i=6 (level=1, group=1);  {'reg_alpha': 1, 'reg_lambda': 0, 'func_value': 0.9964695169726616}\n",
      "> i=7 (level=1, group=1);  {'reg_alpha': 1, 'reg_lambda': 1, 'func_value': 0.9966067382419584}\n",
      "> i=8 (level=1, group=1);  {'reg_alpha': 1, 'reg_lambda': 10, 'func_value': 0.9966057701906758}\n",
      "> i=9 (level=1, group=1);  {'reg_alpha': 1, 'reg_lambda': 100, 'func_value': 0.9943734741847949}\n",
      "> i=10 (level=1, group=1);  {'reg_alpha': 1, 'reg_lambda': 500, 'func_value': 0.99446961377779}\n",
      "> i=11 (level=1, group=1);  {'reg_alpha': 10, 'reg_lambda': 0, 'func_value': 0.9859550884708117}\n",
      "> i=12 (level=1, group=1);  {'reg_alpha': 10, 'reg_lambda': 1, 'func_value': 0.986021763002895}\n",
      "> i=13 (level=1, group=1);  {'reg_alpha': 10, 'reg_lambda': 10, 'func_value': 0.9861486079725074}\n",
      "> i=14 (level=1, group=1);  {'reg_alpha': 10, 'reg_lambda': 100, 'func_value': 0.9866287765344369}\n",
      "> i=15 (level=1, group=1);  {'reg_alpha': 10, 'reg_lambda': 500, 'func_value': 0.9867029837155623}\n",
      "> i=16 (level=1, group=1);  {'reg_alpha': 100, 'reg_lambda': 0, 'func_value': 0.9154047664425022}\n",
      "> i=17 (level=1, group=1);  {'reg_alpha': 100, 'reg_lambda': 1, 'func_value': 0.9154047664425022}\n",
      "> i=18 (level=1, group=1);  {'reg_alpha': 100, 'reg_lambda': 10, 'func_value': 0.9154047664425022}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i=19 (level=1, group=1);  {'reg_alpha': 100, 'reg_lambda': 100, 'func_value': 0.9154047664425022}\n",
      "> i=20 (level=1, group=1);  {'reg_alpha': 100, 'reg_lambda': 500, 'func_value': 0.9139639431148865}\n",
      "> i=21 (level=1, group=1);  {'reg_alpha': 500, 'reg_lambda': 0, 'func_value': 0.5}\n",
      "> i=22 (level=1, group=1);  {'reg_alpha': 500, 'reg_lambda': 1, 'func_value': 0.5}\n",
      "> i=23 (level=1, group=1);  {'reg_alpha': 500, 'reg_lambda': 10, 'func_value': 0.5}\n",
      "> i=24 (level=1, group=1);  {'reg_alpha': 500, 'reg_lambda': 100, 'func_value': 0.5}\n",
      "> i=25 (level=1, group=1);  {'reg_alpha': 500, 'reg_lambda': 500, 'func_value': 0.5}\n",
      "  best so far = {'reg_alpha': 0, 'reg_lambda': 0, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'reg_alpha': 0, 'reg_lambda': 0, 'func_value': 0.9981432776401331}\n",
      "> i=26 (level=2, group=2);  {'reg_alpha': 0.5, 'reg_lambda': 0.0, 'func_value': 0.9972458638496373}\n",
      "> i=27 (level=2, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.5, 'func_value': 0.9979012043162987}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.0, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.0, 'func_value': 0.9981432776401331}\n",
      "> i=28 (level=3, group=2);  {'reg_alpha': 0.25, 'reg_lambda': 0.0, 'func_value': 0.9979377785038162}\n",
      "> i=29 (level=3, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.25, 'func_value': 0.9980766031080497}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.0, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.0, 'func_value': 0.9981432776401331}\n",
      "> i=30 (level=4, group=2);  {'reg_alpha': 0.125, 'reg_lambda': 0.0, 'func_value': 0.9975931522472402}\n",
      "> i=31 (level=4, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.125, 'func_value': 0.9980390608692495}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.0, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.0, 'func_value': 0.9981432776401331}\n",
      "> i=32 (level=5, group=2);  {'reg_alpha': 0.0625, 'reg_lambda': 0.0, 'func_value': 0.9978711039717328}\n",
      "> i=33 (level=5, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.0625, 'func_value': 0.997907345391622}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.0, 'func_value': 0.9981432776401331}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.0, 'func_value': 0.9981432776401331}\n",
      "> i=34 (level=6, group=2);  {'reg_alpha': 0.03125, 'reg_lambda': 0.0, 'func_value': 0.997972749356397}\n",
      "> i=35 (level=6, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "> i=36 (level=6, group=3);  {'reg_alpha': 0.03125, 'reg_lambda': 0.03125, 'func_value': 0.9979743526913337}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "> i=37 (level=7, group=2);  {'reg_alpha': 0.015625, 'reg_lambda': 0.03125, 'func_value': 0.9979733846400511}\n",
      "> i=38 (level=7, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.015625, 'func_value': 0.998075635056767}\n",
      "> i=39 (level=7, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.046875, 'func_value': 0.9981468170776348}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "> i=40 (level=8, group=2);  {'reg_alpha': 0.0078125, 'reg_lambda': 0.03125, 'func_value': 0.9980435683580338}\n",
      "> i=41 (level=8, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.0234375, 'func_value': 0.9977604133578977}\n",
      "> i=42 (level=8, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.0390625, 'func_value': 0.998045201944573}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "> i=43 (level=9, group=2);  {'reg_alpha': 0.00390625, 'reg_lambda': 0.03125, 'func_value': 0.9980445666609189}\n",
      "> i=44 (level=9, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.02734375, 'func_value': 0.9977973203130436}\n",
      "> i=45 (level=9, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.03515625, 'func_value': 0.9980795072618971}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "> i=46 (level=10, group=2);  {'reg_alpha': 0.001953125, 'reg_lambda': 0.03125, 'func_value': 0.9980461699958555}\n",
      "> i=47 (level=10, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.029296875, 'func_value': 0.997798288364326}\n",
      "> i=48 (level=10, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.033203125, 'func_value': 0.9980785392106146}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "> i=49 (level=11, group=2);  {'reg_alpha': 0.0009765625, 'reg_lambda': 0.03125, 'func_value': 0.9979425885086262}\n",
      "> i=50 (level=11, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.0302734375, 'func_value': 0.9977630149957193}\n",
      "> i=51 (level=11, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.0322265625, 'func_value': 0.9980785392106146}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "> i=52 (level=12, group=2);  {'reg_alpha': 0.00048828125, 'reg_lambda': 0.03125, 'func_value': 0.9980102613435946}\n",
      "> i=53 (level=12, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.03076171875, 'func_value': 0.9977630149957193}\n",
      "> i=54 (level=12, group=2);  {'reg_alpha': 0.0, 'reg_lambda': 0.03173828125, 'func_value': 0.9981801543436764}\n",
      "  best so far = {'reg_alpha': 0.0, 'reg_lambda': 0.03125, 'func_value': 0.998180456859702}\n",
      "cross grid search completed...\n",
      "Best Param =  {'reg_alpha': 0.0, 'reg_lambda': 0.03125}\n",
      "    func_value  reg_alpha  reg_lambda\n",
      "34    0.998180        0.0    0.031250\n",
      "53    0.998180        0.0    0.031738\n",
      "38    0.998147        0.0    0.046875\n",
      "0     0.998143        0.0    0.000000\n",
      "44    0.998080        0.0    0.035156\n",
      "47    0.998079        0.0    0.033203\n",
      "50    0.998079        0.0    0.032227\n",
      "28    0.998077        0.0    0.250000\n",
      "41    0.998045        0.0    0.039062\n",
      "30    0.998039        0.0    0.125000\n",
      "32    0.997907        0.0    0.062500\n",
      "26    0.997901        0.0    0.500000\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0001220703125, n_estimators=132, n_jobs=4,\n",
      "               num_leaves=31, objective=None, random_state=123, reg_alpha=0.0,\n",
      "               reg_lambda=0.03125, silent=True, subsample=0.2,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n",
      "> i=1 (level=1, group=1);  {'learning_rate': 0.005, 'func_value': 0.9978005572345194}\n",
      "> i=2 (level=1, group=1);  {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=3 (level=1, group=1);  {'learning_rate': 0.2, 'func_value': 0.9976905321559408}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=4 (level=2, group=2);  {'learning_rate': 0.022360679774997897, 'func_value': 0.9978011925181736}\n",
      "> i=5 (level=2, group=2);  {'learning_rate': 0.14142135623730953, 'func_value': 0.9980076899573754}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=6 (level=3, group=2);  {'learning_rate': 0.047287080450158794, 'func_value': 0.9978335919845354}\n",
      "> i=7 (level=3, group=2);  {'learning_rate': 0.11892071150027213, 'func_value': 0.9977277718787153}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=8 (level=4, group=2);  {'learning_rate': 0.06876560219336321, 'func_value': 0.9978345600358178}\n",
      "> i=9 (level=4, group=2);  {'learning_rate': 0.10905077326652578, 'func_value': 0.9981477851289172}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i=10 (level=5, group=2);  {'learning_rate': 0.0829250277017519, 'func_value': 0.9980779039269605}\n",
      "> i=11 (level=5, group=2);  {'learning_rate': 0.1044273782427414, 'func_value': 0.9978355280871003}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=12 (level=6, group=2);  {'learning_rate': 0.09106318010137353, 'func_value': 0.9980419952746997}\n",
      "> i=13 (level=6, group=2);  {'learning_rate': 0.10218971486541167, 'func_value': 0.9976565898578477}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=14 (level=7, group=2);  {'learning_rate': 0.09542702976692376, 'func_value': 0.9980795072618971}\n",
      "> i=15 (level=7, group=2);  {'learning_rate': 0.10108892860517006, 'func_value': 0.9976228895725751}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=16 (level=8, group=2);  {'learning_rate': 0.09768675947482533, 'func_value': 0.9979374759877905}\n",
      "> i=17 (level=8, group=2);  {'learning_rate': 0.10054299011128029, 'func_value': 0.9976944346126736}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=18 (level=9, group=2);  {'learning_rate': 0.09883661238368369, 'func_value': 0.9980112293948771}\n",
      "> i=19 (level=9, group=2);  {'learning_rate': 0.10027112750502026, 'func_value': 0.9980426305583538}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=20 (level=10, group=2);  {'learning_rate': 0.09941660443994438, 'func_value': 0.9981497212314823}\n",
      "> i=21 (level=10, group=2);  {'learning_rate': 0.10013547198921083, 'func_value': 0.9980798400295254}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=22 (level=11, group=2);  {'learning_rate': 0.0997078755364612, 'func_value': 0.9980099285759664}\n",
      "> i=23 (level=11, group=2);  {'learning_rate': 0.10006771306930665, 'func_value': 0.9980795072618971}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=24 (level=12, group=2);  {'learning_rate': 0.09985383094126193, 'func_value': 0.9980092932923122}\n",
      "> i=25 (level=12, group=2);  {'learning_rate': 0.10003385080526825, 'func_value': 0.9981458490263522}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "  best so far = {'learning_rate': 0.1, 'func_value': 0.998180456859702}\n",
      "> i=26 (level=13, group=2);  {'learning_rate': 0.09992688874435246, 'func_value': 0.9982147621770263}\n",
      "> i=27 (level=13, group=2);  {'learning_rate': 0.10001692397053023, 'func_value': 0.9980099285759663}\n",
      "  best so far = {'learning_rate': 0.09992688874435246, 'func_value': 0.9982147621770263}\n",
      "  best so far = {'learning_rate': 0.09992688874435246, 'func_value': 0.9982147621770263}\n",
      "> i=28 (level=14, group=2);  {'learning_rate': 0.09989035316368074, 'func_value': 0.998145213742698}\n",
      "> i=29 (level=14, group=2);  {'learning_rate': 0.099963437688163, 'func_value': 0.9980076597057728}\n",
      "  best so far = {'learning_rate': 0.09992688874435246, 'func_value': 0.9982147621770263}\n",
      "  best so far = {'learning_rate': 0.09992688874435246, 'func_value': 0.9982147621770263}\n",
      "> i=30 (level=15, group=2);  {'learning_rate': 0.09990861928392965, 'func_value': 0.9980092932923121}\n",
      "> i=31 (level=15, group=2);  {'learning_rate': 0.09994516154555995, 'func_value': 0.9980422675391228}\n",
      "  best so far = {'learning_rate': 0.09992688874435246, 'func_value': 0.9982147621770263}\n",
      "  best so far = {'learning_rate': 0.09992688874435246, 'func_value': 0.9982147621770263}\n",
      "> i=32 (level=16, group=2);  {'learning_rate': 0.09991775359658114, 'func_value': 0.9980092932923121}\n",
      "> i=33 (level=16, group=2);  {'learning_rate': 0.09993602472731994, 'func_value': 0.9982500355456331}\n",
      "  best so far = {'learning_rate': 0.09993602472731994, 'func_value': 0.9982500355456331}\n",
      "  best so far = {'learning_rate': 0.09993602472731994, 'func_value': 0.9982500355456331}\n",
      "> i=34 (level=17, group=2);  {'learning_rate': 0.09993145663143191, 'func_value': 0.9982147621770263}\n",
      "> i=35 (level=17, group=2);  {'learning_rate': 0.0999405930320261, 'func_value': 0.9979406826576638}\n",
      "  best so far = {'learning_rate': 0.09993602472731994, 'func_value': 0.9982500355456331}\n",
      "  best so far = {'learning_rate': 0.09993602472731994, 'func_value': 0.9982500355456331}\n",
      "> i=36 (level=18, group=2);  {'learning_rate': 0.09993374065327425, 'func_value': 0.9982500355456331}\n",
      "> i=37 (level=18, group=2);  {'learning_rate': 0.09993830885357016, 'func_value': 0.9982500355456331}\n",
      "  best so far = {'learning_rate': 0.09993602472731994, 'func_value': 0.9982500355456331}\n",
      "cross grid search completed...\n",
      "Best Param =  {'learning_rate': 0.09993602472731994}\n",
      "    func_value  learning_rate\n",
      "32    0.998250       0.099936\n",
      "35    0.998250       0.099934\n",
      "33    0.998215       0.099931\n",
      "25    0.998215       0.099927\n",
      "1     0.998180       0.100000\n",
      "19    0.998150       0.099417\n",
      "8     0.998148       0.109051\n",
      "24    0.998146       0.100034\n",
      "27    0.998145       0.099890\n",
      "13    0.998080       0.095427\n",
      "22    0.998080       0.100068\n",
      "9     0.998078       0.082925\n",
      "18    0.998043       0.100271\n",
      "30    0.998042       0.099945\n",
      "11    0.998042       0.091063\n",
      "4     0.998008       0.141421\n",
      "15    0.997937       0.097687\n",
      "5     0.997834       0.047287\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.09993602472731994,\n",
      "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0001220703125, n_estimators=225, n_jobs=4,\n",
      "               num_leaves=31, objective=None, random_state=123, reg_alpha=0.0,\n",
      "               reg_lambda=0.03125, silent=True, subsample=0.2,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n",
      "Final Validatoin Score =  0.9982500355456331\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.09993602472731994,\n",
      "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0001220703125, n_estimators=225, n_jobs=4,\n",
      "               num_leaves=31, objective=None, random_state=123, reg_alpha=0.0,\n",
      "               reg_lambda=0.03125, silent=True, subsample=0.2,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n",
      "Train\n",
      "AUC = 1.0, Accuracy = 1.0\n",
      "Test\n",
      "AUC = 0.9973628100100999, Accuracy = 0.97\n",
      "Final Validatoin Score =  0.997386\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=None, n_estimators=292,\n",
      "              n_jobs=4, nthread=None, objective='binary:logistic',\n",
      "              random_state=123, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              seed=None, silent=True, subsample=1)\n",
      "Train\n",
      "AUC = 0.9999895554812834, Accuracy = 0.99875\n",
      "Test\n",
      "AUC = 0.9974189204354169, Accuracy = 0.965\n",
      "  feature  importance    cumsum\n",
      "0      x1    0.586379  0.586379\n",
      "1      x2    0.413621  1.000000\n"
     ]
    }
   ],
   "source": [
    "if __DEBUG_MODE__:\n",
    "    import sys\n",
    "    sys.path.append(\"../\")\n",
    "    import utils\n",
    "\n",
    "    # test dataset\n",
    "    if True:\n",
    "        #--- dataset for classification ------------\n",
    "        np.random.seed(seed = 123)\n",
    "\n",
    "        NN = 1000 # the number of data points\n",
    "        x1 = np.random.uniform(0, 1, NN)\n",
    "        x2 = np.random.uniform(0, 1, NN)\n",
    "        # y = 2*(x1 - 0.5) - (x2 - 0.5) > 0 # line\n",
    "        # y = x1**2 - x2 > 0 # parabolic 1\n",
    "        y = 2*x1*(1-x1) - x2 > 0 # parabolic 2\n",
    "        # y = ((x1 - 0.5)**2 + (x2 - 0.5)**2 - 0.3**2) > 0 # circle\n",
    "\n",
    "        # dataset\n",
    "        df = pd.DataFrame({'x1':x1, 'x2':x2, 'y':y})\n",
    "        for n in range(1,0): # add uncorrelated features for test\n",
    "            df['r%s'%n] = np.random.uniform(0, 1, NN)\n",
    "\n",
    "        # train, test\n",
    "        train, test = train_test_split(df, test_size = 0.2)\n",
    "        target = ['y']\n",
    "        features = [f for f in df.columns if f not in target]\n",
    "        print(len(features))\n",
    "        features\n",
    "    else:\n",
    "        #--- dataset for regression ----------------\n",
    "        np.random.seed(seed = 123)\n",
    "        x_0 = np.linspace(0,  5, num=1000, endpoint=False); r_0 = np.random.normal(0, 0.3, len(x_0))\n",
    "        x_1 = np.linspace(5, 10, num=1000, endpoint=False); r_1 = np.random.normal(0, 0.3, len(x_1))\n",
    "        y0 = np.concatenate((np.sin(x_0)+5, np.sin(4*x_1)))\n",
    "        # y0 = np.concatenate((np.sin(x_0), np.sin(1*x_1)))\n",
    "\n",
    "        x = np.concatenate((x_0, x_1))\n",
    "        y = y0 + np.concatenate((r_0, r_1))\n",
    "\n",
    "        df = pd.DataFrame({'x':x, 'y0':y0, 'y':y})\n",
    "\n",
    "        # train, test\n",
    "        train, test = train_test_split(df, test_size = 0.2)\n",
    "        features = ['x']\n",
    "        target = ['y']\n",
    "\n",
    "    #--- LigthGBM -----------------------------------------------------------------\n",
    "    eval_metric = 'auc'; MIN_MAX = 'max'; lgbmodel = LGBMClassifier(learning_rate = 0.1, n_jobs = 4, random_state = 123) # classification \n",
    "    # eval_metric = 'rmse'; MIN_MAX = 'min'; lgbmodel = LGBMRegressor(learning_rate = 0.1, n_jobs = 4, random_state = 123) # regression\n",
    "\n",
    "    params_schedule = [\n",
    "        #ref) https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "        #ref) https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "        #ref) https://www.reddit.com/r/MachineLearning/comments/aspx8x/d_methods_for_hyperparameter_tuning_with_lightgbm/\n",
    "        {'learning_rate': ['log', [0.1]]},\n",
    "\n",
    "        {'num_leaves': ['int', [8, 31, 128, 1000]],  # uni / log / int\n",
    "    #      'min_child_samples': ['int', [0, 20, 200]]}, # min_data_in_leaf (uni / log / int)\n",
    "#          'min_child_samples': ['int', [0, 10, 20, 50, 100, 200, 500, 1000]]}, # min_data_in_leaf (uni / log / int)\n",
    "         'min_child_samples': ['int', [0, 10, 20, 50, 100, 200]]}, # min_data_in_leaf (uni / log / int)\n",
    "    #          'min_child_weight': ['log', [0.001, 1000]]}, # min_sum_hessian_in_leaf (uni / log / int)\n",
    "        {'min_split_gain': ['uni', [0, 1, 3, 10, 30, 100, 300, 1000]]}, #min_gain_to_split (uni / log / int)\n",
    "        {'subsample': ['uni', [0.2,0.4,0.6,0.8,1.0]], # bagging_fraction\n",
    "    #      'subsample_freq': ['int', [0,10,100]], # bagging_freq\n",
    "         'colsample_bytree': ['uni', [0.2, 0.4, 0.6, 0.8, 1.0]]},  # feature_fraction (uni / log / int)\n",
    "        {'reg_alpha': ['uni', [0, 1, 10, 100, 500]], # lambda_l1 \n",
    "         'reg_lambda': ['uni', [0, 1, 10, 100, 500]]}, # lambda_l2 (uni / log / int)\n",
    "\n",
    "        {'learning_rate': ['log', [0.005, 0.1, 0.2]]} # uni / log / int\n",
    "    ]\n",
    "    lgbmodel, test_pred_lgb = xgrid_search_boosting(train, test, features, target, params_schedule, lgbmodel, eval_metric, MIN_MAX,\n",
    "                                CV_MODE = 'cross validation 1', N_FOLD = 5, N_BOOST_ROUND = 10000, EARLY_STOPPING = 50, RAND_SEED = 123)\n",
    "    print('Train'); utils.eval_model_scores(lgbmodel, train, features, target)\n",
    "    print('Test'); utils.eval_model_scores(lgbmodel, test, features, target)\n",
    "    \n",
    "    #--- XGBoost -----------------------------------------------------------------\n",
    "    eval_metric = 'auc'; MIN_MAX = 'max'; xgbmodel = XGBClassifier(learning_rate = 0.1, n_jobs = 4, random_state = 123) # classification \n",
    "#     eval_metric = 'rmse'; MIN_MAX = 'min'; xgbmodel = XGBRegressor(learning_rate = 0.1, n_jobs = 4, random_state = 123) # regression\n",
    "\n",
    "    params_schedule = [\n",
    "#         #ref) https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "#         {'learning_rate': ['log', [0.1]]},\n",
    "\n",
    "#         {'max_depth': ['int', [3, 5, 7, 9, 11]], # uni / log / int\n",
    "#          'min_child_weight': ['log', [1, 10, 100, 1000]]}, # uni / log / int\n",
    "#         {'gamma': ['log', [0, 0.001, 1, 1000]]}, # uni / log / int\n",
    "#         {'subsample': ['uni', [0.2, 0.4, 0.6, 0.8, 1.0]],  # uni / log / int\n",
    "#          'colsample_bytree': ['uni', [0.2, 0.4, 0.6, 0.8, 1.0]]},  # uni / log / int\n",
    "#         {'reg_alpha': ['log', [0, 0.001, 1, 1000]],\n",
    "#          'reg_lambda': ['log', [1, 10, 100, 1000]]},  # uni / log / int\n",
    "\n",
    "#         {'learning_rate': ['log', [0.005, 0.1, 0.2]]} # uni / log / int\n",
    "    ]\n",
    "\n",
    "    xgbmodel, test_pred_xgb = xgrid_search_boosting(train, test, features, target, params_schedule, xgbmodel, eval_metric, MIN_MAX,\n",
    "                                CV_MODE = 'cross validation 1', N_FOLD = 5, N_BOOST_ROUND = 10000, EARLY_STOPPING = 50, RAND_SEED = 123)\n",
    "    print('Train'); utils.eval_model_scores(xgbmodel, train, features, target)\n",
    "    print('Test'); utils.eval_model_scores(xgbmodel, test, features, target)\n",
    "    print(utils.feature_importance_xgboost(features, xgbmodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
